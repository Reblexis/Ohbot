# Vision

## Introduction
This is an experiment to create a human-like agent using artificial intelligence.
With the current rise of language models, it is now possible to use them as a brain for an agent.
It is also possible to process audio and visual input and extract valuable information from it which
can be later combined with the brain itself.

As the available technology improves and new research is done, I want to continuously update the robot,
so it will eventually match state-of-the-art performance.

## Short-term goals
- [x] Implement simple brain using a language model
- [x] Create base classes for the project
- [x] Implement real-time speech recognition
- [x] Implement speech synthesis
- [ ] Improve processing speed
- [ ] Add more parallelization
- [ ] Use locally run language model as a brain
- [ ] Implement long-term memory

## Long-term goals (not achievable with current technology)
- [ ] Run all aspects of the robot locally
- [ ] Create more general vision, hearing and speech modules (f.x. data extraction from camera feed via transformers)
- [ ] Achieve real-time learning
- [ ] Create more complex brain (similar to the one of a human)