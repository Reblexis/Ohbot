# Vision

## Introduction
This is an experiment to create a human-like agent using artificial intelligence.
With the current rise of language models, it is now possible to use them as a brain for an agent.
It is also possible to process audio and visual input and extract valuable information from it which
can be later combined with the brain itself.

As the available technology improves and new research is done, I want to continuously update the robot,
so it could eventually match state-of-the-art performance.

## Short-term goals 
These goals should be achievable with current technology.
- [x] Implement simple brain using a language model
- [x] Create base classes for the project
- [x] Implement real-time speech recognition
- [x] Implement speech synthesis
- [ ] Improve processing speed
- [ ] Add more parallelization
- [ ] Use locally run language model as a brain
- [ ] Implement long-term memory
- [ ] Improve the general structure of the project (add more abstraction)

## Long-term goals (not achievable with discovered technology)
These goals are not achievable with the current technology but may be in the future.
- [ ] Run all aspects of the robot locally
- [ ] Create more general vision, hearing and speech modules (f.x. data extraction from camera feed via transformers)
- [ ] Achieve real-time learning
- [ ] Create more complex brain (similar to the one of a human)